---
title: "MGSC 310 Final Project Rough Draft"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
# As long as you are working in a Rstudio Project file, you shouldn't need to 'hard code' directories like this 
# change to your own working directory
# knitr::opts_knit$set(root.dir = 'C:/Users/hersh/Dropbox/Chapman/Teaching/MGSC_310/Fall_2019/problem_sets')
# setwd('C:/Users/hersh/Dropbox/Chapman/Teaching/MGSC_310/Fall_2019/problem_sets')

# set seed to your own favorite number
set.seed(1818)
options(width=70)
options(scipen=99)
rm(list = ls())


# general rchunk code options

# this sets text to small
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=TRUE, size = "vsmall")  
opts_chunk$set(message = FALSE,                                          
               warning = FALSE,
               # "caching" stores objects in code chunks and only rewrites if you change things
               cache = TRUE,                               
               # automatically downloads dependency files
               autodep = TRUE,
               # 
               cache.comments = FALSE,
               # 
               collapse = TRUE,
               fig.width = 5,  
               fig.height = 4,
               fig.align='center')


```

### Importing Libraries
```{r}
library(magrittr)
library('rsample')
library('tidyverse')
library('ISLR')
library('yardstick')
library('ggplot2')
library('plotROC')
library('rsample')
library('glmnet')
library('glmnetUtils')
library('forcats')
library('broom')

```

### Cleaning the dataset and Creating training and testing data sets (working on clustering ages and countries together to help the model perform better by the time we submit our final project)

```{r}
lego_sets <- read.csv("lego_sets.csv")

lego_clean <- lego_sets %>% select(-c(prod_long_desc,theme_name,prod_desc,set_name)) %>% mutate(
  ages = factor(ages), review_difficulty = factor(review_difficulty), country = factor(country)
) %>% drop_na()

lego_split <- initial_split(lego_clean, p = 0.75)
lego_train <- training(lego_split)
lego_test <- testing(lego_split)
```

### Creating a GLM model
```{r}
glm_mod <- glm(list_price ~ ages + piece_count + num_reviews + play_star_rating + review_difficulty + star_rating + 
                  val_star_rating + country, 
           data = lego_train)
```

### Generating predictions
```{r}
preds_train_glm <- predict(glm_mod,
                          newdata = lego_train)
```

### Creating a results data frame
```{r}
results_train_glm <- data.frame(
  preds = preds_train_glm,
  true = lego_train$list_price
)
```

### Plotting the true and predicted values
```{r}
ggplot(results_train_glm, 
       aes(x = true, y = preds)) +
  geom_point(alpha = 1/2, size = 4) +
  geom_smooth(color = "red")
```

### Evaluating the metrics
```{r}
metrics(results_train_glm, preds, true)
```

Can we get better error rates with a different model?


### Enet Model
```{r}
enet_mod <- cva.glmnet(list_price ~ ages + piece_count + num_reviews + play_star_rating + review_difficulty + star_rating + 
                  val_star_rating + country, 
           data = lego_train,
                       alpha = seq(0,1, by = 0.05))

plot(enet_mod)
```


### Minloss plot to determine Lasso vs. Ridge
```{r}
minlossplot(enet_mod, 
            cv.type = "min")
```

We determine that this is a lasso model because there is the least amount of error when alpha is equal to 1.  This means that only a few of the variables we chose are highly influential to the model.

### Creating the Lasso Model
```{r}
lasso_mod <- cv.glmnet(list_price ~ ages + piece_count + num_reviews + play_star_rating + review_difficulty + star_rating + 
                  val_star_rating + country, 
                  data = lego_train,
                  alpha = 1)

plot(lasso_mod)
```
lambda.1se does not increase the mean-squared error much compared to lambda.min.  As such, we would choose the lambda.1se value for lambda in order to increase the shrinkage in our model.

### Which variables are the most influential?
```{r}
library(coefplot)
coefpath(lasso_mod)
```
It appears that the 'ages' variable is the most influential to the model because it shrinks last.


#### SHOULD WE KEEP THIS?

```{r}
print(lasso_mod$lambda.1se)
coef(lasso_mod, 
     s = lasso_mod$lambda.min)
```

## THESE FACTORS WILL BE CLEANED UP AS WE REFINE OUR MODEL
















